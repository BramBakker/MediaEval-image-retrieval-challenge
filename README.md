Image retrieval techniques 

 

My method consists of using CLIP for image retrieval. I made two to the normal processing. I used both the headline and article text, and also the model long-clip, which is optimized for longer text. 

 

The specific method of incorporating categories in the embedings of the news articles I used comes from a paper from Song, Rui, et al. "Improving News Retrieval with a Learnable Alignment Module for Multimodal Text–Image Matching." Electronics 14.15 (2025): 3098.  

https://www.mdpi.com/2079-9292/14/15/3098 

 

There are three different loss components, the contrastive loss between text and corresponding image embedding, the label loss, which further projects the embedding, and then the KL divergence loss, which makes sure the embeddings generated by the model aren’t too far from the original embeddings generated by CLIP. 

 

 

 

f three different components, I use the article text and a summarization tool, so the image matches the entire content of the article, then I finetune a learnable alignment module over clip using the public n24 news dataset, of 24 news categories. Then I use the long clip model to get all the yfcc100million embeddings in a 50 gb embedding file, and search through that using rough search for each text file, I also predict the corresponding news category. 

 
